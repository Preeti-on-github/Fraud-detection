# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tJxq3_XBJj2pWMUI0YlphftiMTGb_1nR
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from imblearn.over_sampling import SMOTE


# Load the dataset
df = pd.read_csv('creditcard.csv')

#Examine the dataset's structure and check for missing values:
print(df.info())
print(df.describe())

"""Feature Selection:

The dataset includes 30 features: 'Time', 'Amount', and 28 principal components (V1 to V28).
For logistic regression, scaling the 'Amount' and 'Time' features is considered

Address any missing values or anomalies as needed.
Feature Selection:


The dataset includes 30 features: 'Time', 'Amount', and 28 principal components (V1 to V28).
For logistic regression, consider scaling the 'Amount' and 'Time' features.
Handling Class Imbalance:


Given the imbalance (fraudulent transactions constitute approximately 0.172% of all transactions), apply techniques such as:
Oversampling the minority class using SMOTE (Synthetic Minority Over-sampling Technique).
Undersampling the majority class.
Using class weights in the logistic regression model.
Model Development:

Split the data into training and testing sets:
"""

# Handle missing values
df.fillna(df.mean(), inplace=True)

from sklearn.model_selection import train_test_split

X = df.drop('Class', axis=1)
y = df['Class']

# Scale 'Time' and 'Amount'
scaler = StandardScaler()
X[['Time', 'Amount']] = scaler.fit_transform(X[['Time', 'Amount']])

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)

# Train logistic regression model
model = LogisticRegression(max_iter=1000, solver='saga', class_weight='balanced')
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluation
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)
conf_matrix = confusion_matrix(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print("Classification Report:")
print(report)
print("Confusion Matrix:")
print(conf_matrix)

"""Key Observations:
Strong Overall Performance:

High precision and recall for both classes, indicating the model is effective in detecting fraudulent and non-fraudulent transactions.
Missed Fraudulent Transactions (FN):

6,683 fraudulent transactions were missed, which could lead to financial loss. If reducing false negatives is a priority, consider optimizing for higher recall for Class 1 (fraudulent transactions).
False Alarms (FP):

2,094 non-fraudulent transactions were flagged as fraudulent. This could lead to inconveniences for customers but is a trade-off for high fraud detection.
Convergence Warning:

The max_iter limit was reached, meaning the coefficients did not fully converge. While this doesn't invalidate the results, increasing max_iter or further scaling the data might improve the model's performance slightly.

Improvement process:

Model Refinement: Experiment with other algorithms (e.g., Random Forests, XGBoost) to compare performance and handle complex relationships in the data.
"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score

# Train Random Forest Classifier without SMOTE
rf_model = RandomForestClassifier(
    n_estimators=100, random_state=42, class_weight='balanced', n_jobs=-1
)
rf_model.fit(X_train, y_train)

# Predictions and probabilities
y_rf_pred = rf_model.predict(X_test)
y_rf_prob = rf_model.predict_proba(X_test)[:, 1]

# Evaluate Random Forest model
rf_accuracy = accuracy_score(y_test, y_rf_pred)
rf_classification_report = classification_report(y_test, y_rf_pred)
rf_conf_matrix = confusion_matrix(y_test, y_rf_pred)
rf_roc_auc = roc_auc_score(y_test, y_rf_prob)

# Display updated model results
optimization_results = {
    "Random Forest Accuracy": rf_accuracy,
    "Random Forest Classification Report": rf_classification_report,
    "Random Forest Confusion Matrix": rf_conf_matrix,
    "Random Forest ROC-AUC Score": rf_roc_auc,
}

optimization_results

"""Key Observations:
Outstanding Performance:

The model shows near-perfect classification for both non-fraudulent and fraudulent transactions.
Both precision and recall are effectively 100%, meaning the model can identify fraud and non-fraud cases without errors.
Minimal False Alarms:

Only 15 non-fraudulent transactions were flagged as fraudulent (False Positives), which is negligible given the dataset size.
No Missed Fraudulent Transactions:

All fraudulent transactions were detected (0 False Negatives).
Practical Implications:

The model's high precision ensures customers are not unnecessarily flagged.
High recall for fraudulent transactions ensures no fraudulent activity is missed, making it highly reliable for fraud detection.

Recommendations:
While the model's performance is exceptional, further testing on unseen datasets or real-world data is recommended to validate generalization.
Monitor for potential overfitting due to the perfect metrics, especially if the test data closely mirrors the training set.
"""

